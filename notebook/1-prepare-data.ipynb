{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data\n",
    "\n",
    "Copyright 2019 IBM Corp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "home_dir = \"../data\"\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 20,10\n",
    "rcParams['font.size'] = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pkl file ../data/loan.pkl\n",
      "Done\n",
      "Shape (2260668, 145)\n"
     ]
    }
   ],
   "source": [
    "csv_file = os.path.join(home_dir, \"loan.csv\")\n",
    "pkl_file = os.path.join(home_dir, \"loan.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(pkl_file):\n",
    "    print(\"Reading csv file {}\".format(csv_file))\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    \n",
    "    df.to_pickle(pkl_file)\n",
    "    \n",
    "else:    \n",
    "    print(\"Reading pkl file {}\".format(pkl_file))\n",
    "    df = pd.read_pickle(pkl_file)\n",
    "  \n",
    "\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Shape {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fully Paid                                             1041952\n",
      "Current                                                 919695\n",
      "Charged Off                                             261655\n",
      "Late (31-120 days)                                       21897\n",
      "In Grace Period                                           8952\n",
      "Late (16-30 days)                                         3737\n",
      "Does not meet the credit policy. Status:Fully Paid        1988\n",
      "Does not meet the credit policy. Status:Charged Off        761\n",
      "Default                                                     31\n",
      "Name: loan_status, dtype: int64\n",
      "Total loans either Fully Paid or charged off: 1303607\n",
      "Charged off percent: 20.07%\n"
     ]
    }
   ],
   "source": [
    "# Use only those loans that are either Fully Paid or Charged Off\n",
    "\n",
    "print(df.loan_status.value_counts())\n",
    "\n",
    "fully_paid_df = df[df['loan_status'] == 'Fully Paid']\n",
    "charged_off_df = df[df['loan_status'] == 'Charged Off']\n",
    "local_df = fully_paid_df.append(charged_off_df)\n",
    "print(\"Total loans either Fully Paid or charged off: {}\".format(local_df.shape[0]))\n",
    "\n",
    "print(\"Charged off percent: {0:.2f}%\".format(100*charged_off_df.shape[0]/local_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refactor employment length and fill Null values - this might be an important indicator\n",
    "local_df['emp_length'].fillna(value=0, inplace=True)\n",
    "local_df['emp_length'].replace(to_replace='[^0-9]+', value='', inplace=True, regex=True)\n",
    "local_df['emp_length'].replace(to_replace='', value=0, inplace=True)\n",
    "local_df.loc[:,'emp_length'] = local_df.loc[:,'emp_length'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing columns: Index(['id', 'next_pymnt_d', 'member_id', 'url',\n",
      "       'orig_projected_additional_accrued_interest', 'hardship_type',\n",
      "       'hardship_reason', 'hardship_status', 'hardship_last_payment_amount',\n",
      "       'hardship_payoff_balance_amount', 'hardship_start_date',\n",
      "       'hardship_loan_status', 'hardship_dpd', 'hardship_length',\n",
      "       'payment_plan_start_date', 'hardship_end_date', 'deferral_term',\n",
      "       'hardship_amount', 'sec_app_mths_since_last_major_derog',\n",
      "       'sec_app_revol_util', 'revol_bal_joint',\n",
      "       'sec_app_collections_12_mths_ex_med',\n",
      "       'sec_app_chargeoff_within_12_mths', 'sec_app_num_rev_accts',\n",
      "       'sec_app_open_act_il', 'sec_app_open_acc', 'sec_app_mort_acc',\n",
      "       'sec_app_inq_last_6mths', 'sec_app_earliest_cr_line',\n",
      "       'verification_status_joint', 'dti_joint', 'annual_inc_joint',\n",
      "       'debt_settlement_flag_date', 'settlement_status', 'settlement_date',\n",
      "       'settlement_amount', 'settlement_percentage', 'settlement_term', 'desc',\n",
      "       'mths_since_last_record', 'mths_since_recent_bc_dlq',\n",
      "       'mths_since_last_major_derog', 'il_util',\n",
      "       'mths_since_recent_revol_delinq', 'mths_since_rcnt_il', 'all_util',\n",
      "       'total_cu_tl', 'open_acc_6m', 'inq_last_12m', 'open_rv_24m',\n",
      "       'open_il_24m', 'max_bal_bc', 'open_rv_12m', 'inq_fi', 'total_bal_il',\n",
      "       'open_act_il', 'open_il_12m', 'mths_since_last_delinq'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with 30% or more missing entries\n",
    "percent_missing_threshold = 30\n",
    "\n",
    "def null_values(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns={0: 'Missing Values', 1: '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "    return mis_val_table_ren_columns\n",
    "\n",
    "# Remove columns with too many missing values\n",
    "miss_values = null_values(local_df)\n",
    "cols_to_rm = miss_values[miss_values['% of Total Values'] > percent_missing_threshold].index\n",
    "print(\"Removing columns: {}\".format(cols_to_rm))\n",
    "\n",
    "local_df.drop(cols_to_rm, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0.18% of rows because of null entries in date columns\n",
      "(1301293, 87)\n"
     ]
    }
   ],
   "source": [
    "# remove null entries in dates\n",
    "rows = local_df.shape[0]\n",
    "\n",
    "local_df = local_df.loc[~local_df.issue_d.isnull()]\n",
    "local_df = local_df.loc[~local_df.last_pymnt_d.isnull()]\n",
    "local_df = local_df.loc[~local_df.last_pymnt_d.isna()]\n",
    "local_df = local_df.loc[~local_df.earliest_cr_line.isnull()]\n",
    "local_df = local_df.loc[~local_df.last_credit_pull_d.isnull()]\n",
    "print(\"Removed {0:.2f}% of rows because of null entries in date columns\".format(100*(rows - local_df.shape[0])/rows))\n",
    "\n",
    "print(local_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform dates to datetime format\n",
    "\n",
    "local_df['issue_d'] = pd.to_datetime(local_df.issue_d, format='%b-%Y')\n",
    "local_df['last_pymnt_d']  = pd.to_datetime(local_df.last_pymnt_d, format='%b-%Y')\n",
    "local_df['earliest_cr_line']  = pd.to_datetime(local_df.earliest_cr_line, format='%b-%Y')\n",
    "local_df['last_credit_pull_d'] = pd.to_datetime(local_df.last_credit_pull_d, format='%b-%Y')\n",
    "\n",
    "# Number the months from earliest issue_d to latest last_pymnt_d\n",
    "local_df['issue_month'] = local_df.issue_d.apply(lambda x: 12*x.year + x.month).astype(int)\n",
    "local_df['last_p_month']  = local_df.last_pymnt_d.apply(lambda x: 12*x.year + x.month).astype(int)\n",
    "local_df['earliest_cr_line_month']  = local_df.earliest_cr_line.apply(lambda x: 12*x.year + x.month).astype(int)\n",
    "local_df['last_credit_pull_month']  = local_df.last_credit_pull_d.apply(lambda x: 12*x.year + x.month).astype(int)\n",
    "\n",
    "local_df['earliest_cr_line_age'] = (local_df.issue_month - local_df.earliest_cr_line_month).apply(lambda x: max(x,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Issue months from: 0 to: 138\n",
      "Last payment months from: 7 to: 140\n",
      "Issue dates from: Jun-2007 to: Dec-2018\n",
      "Last payment dates from: Jan-2008 to: Feb-2019\n"
     ]
    }
   ],
   "source": [
    "# Normalize so that earliest_issue_month is month 0\n",
    "\n",
    "earliest_issue_month = min(local_df.issue_month)\n",
    "\n",
    "local_df['issue_month']            -= earliest_issue_month\n",
    "local_df['last_p_month']           -= earliest_issue_month\n",
    "local_df['earliest_cr_line_month'] -= earliest_issue_month\n",
    "local_df['last_credit_pull_month'] -= earliest_issue_month\n",
    "\n",
    "# Create dictionaries to map between month numbers and dates\n",
    "unique_i_months = sorted(local_df.issue_month.unique())\n",
    "unique_p_months = sorted(local_df.last_p_month.unique())\n",
    "\n",
    "months = set(unique_i_months + unique_p_months)\n",
    "\n",
    "unique_i_d = sorted(pd.to_datetime(local_df.issue_d.unique()))\n",
    "unique_p_d = sorted(pd.to_datetime(local_df.last_pymnt_d.unique()))\n",
    "\n",
    "dates = set(unique_i_d + unique_p_d)\n",
    "\n",
    "month_to_date = dict(zip(months, dates))\n",
    "date_to_month = dict(zip(dates, months))\n",
    "\n",
    "# Print out some date stats\n",
    "earliest_issue_month = min(unique_i_months)\n",
    "latest_issue_month = max(unique_i_months) \n",
    "earliest_last_payment_month = min(unique_p_months)\n",
    "latest_last_payment_month     = max(unique_p_months)\n",
    "\n",
    "earliest_issue_d = min(unique_i_d)\n",
    "latest_issue_d = max(unique_i_d) \n",
    "earliest_last_payment_d = min(unique_p_d)\n",
    "latest_last_payment_d     = max(unique_p_d)\n",
    "\n",
    "print(\"Issue months from: {} to: {}\".format(earliest_issue_month, latest_issue_month))\n",
    "print(\"Last payment months from: {} to: {}\".format(earliest_last_payment_month, latest_last_payment_month))\n",
    "\n",
    "print(\"Issue dates from: {} to: {}\".format(earliest_issue_d.strftime(\"%b-%Y\"), latest_issue_d.strftime(\"%b-%Y\")))\n",
    "print(\"Last payment dates from: {} to: {}\".format(earliest_last_payment_d.strftime(\"%b-%Y\"), latest_last_payment_d.strftime(\"%b-%Y\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>TotalGain</th>\n",
       "      <th>PvGain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>26.44</td>\n",
       "      <td>26.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>40000</td>\n",
       "      <td>40000</td>\n",
       "      <td>856.68</td>\n",
       "      <td>795.488571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>215.79</td>\n",
       "      <td>200.376429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>4500</td>\n",
       "      <td>4500</td>\n",
       "      <td>49.22</td>\n",
       "      <td>45.704286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>8425</td>\n",
       "      <td>8425</td>\n",
       "      <td>310.15</td>\n",
       "      <td>287.996429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loan_amnt  funded_amnt  TotalGain      PvGain\n",
       "100      30000        30000      26.44   26.440000\n",
       "152      40000        40000     856.68  795.488571\n",
       "170      20000        20000     215.79  200.376429\n",
       "186       4500         4500      49.22   45.704286\n",
       "215       8425         8425     310.15  287.996429"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate analytical quantities\n",
    "analytics = ['TotalGain','PvGain' ,'LoanStatus', 'LifeOfLoan']\n",
    "\n",
    "# Total Gain\n",
    "#   principal received minus funded amount\n",
    "#   plus interest\n",
    "#   plus recoveries in case of default\n",
    "#   minus collection recovery fee\n",
    "local_df['TotalGain'] = local_df['total_rec_prncp'] - local_df['funded_amnt'] \\\n",
    "                        + local_df['total_rec_int'] + local_df['recoveries'] - local_df['collection_recovery_fee']\n",
    "\n",
    "# loan_status: \n",
    "#    ChargedOff = 1\n",
    "#    Fully Paid = 0\n",
    "local_df['LoanStatus'] = (local_df['loan_status']!='Fully Paid').astype(int)\n",
    "\n",
    "\n",
    "# Life of loan\n",
    "#   begins on issue month\n",
    "#   ends on last payment month\n",
    "#   ... so if loan issued on month 0 and ends on month 1, then there is one payment recieved.\n",
    "local_df['LifeOfLoan'] = local_df.last_p_month - local_df.issue_month\n",
    "\n",
    "\n",
    "# Present Value - Assume equal monthly payments totalling total gain for present value calculation\n",
    "\n",
    "ann_rate = 2.0\n",
    "\n",
    "mo_rate = ann_rate/12\n",
    "\n",
    "def pv(q, rate):\n",
    "    discount = 1/(1+rate)\n",
    "    pv = 0\n",
    "    for value in reversed(q):\n",
    "        pv *= discount\n",
    "        #print(pv)\n",
    "        pv += value\n",
    "        #print(pv)\n",
    "    return pv\n",
    "\n",
    "\n",
    "def calc_pv(row):\n",
    "    if row['LifeOfLoan'] == 0:\n",
    "        return row['TotalGain']\n",
    "    eq_pymnt = row['TotalGain'] / row['LifeOfLoan']\n",
    "    q = [eq_pymnt]*int(row['LifeOfLoan'])\n",
    "    return pv(q, mo_rate)\n",
    "\n",
    "local_df['PvGain'] = local_df.apply(calc_pv, axis=1)\n",
    "\n",
    "local_df[[ 'loan_amnt','funded_amnt','TotalGain','PvGain']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TotalGain', 'PvGain', 'LoanStatus', 'LifeOfLoan']\n",
      "['LifeOfLoan', 'LoanStatus', 'PvGain', 'TotalGain', 'acc_now_delinq', 'acc_open_past_24mths', 'addr_state', 'annual_inc', 'application_type', 'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths', 'collection_recovery_fee', 'collections_12_mths_ex_med', 'debt_settlement_flag', 'delinq_2yrs', 'delinq_amnt', 'disbursement_method', 'dti', 'earliest_cr_line', 'earliest_cr_line_age', 'earliest_cr_line_month', 'emp_length', 'emp_title', 'funded_amnt', 'funded_amnt_inv', 'grade', 'hardship_flag', 'home_ownership', 'initial_list_status', 'inq_last_6mths', 'installment', 'int_rate', 'issue_d', 'issue_month', 'last_credit_pull_d', 'last_credit_pull_month', 'last_p_month', 'last_pymnt_amnt', 'last_pymnt_d', 'loan_amnt', 'loan_status', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'mths_since_recent_inq', 'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl', 'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m', 'open_acc', 'out_prncp', 'out_prncp_inv', 'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'policy_code', 'pub_rec', 'pub_rec_bankruptcies', 'purpose', 'pymnt_plan', 'recoveries', 'revol_bal', 'revol_util', 'sub_grade', 'tax_liens', 'term', 'title', 'tot_coll_amt', 'tot_cur_bal', 'tot_hi_cred_lim', 'total_acc', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit', 'total_pymnt', 'total_pymnt_inv', 'total_rec_int', 'total_rec_late_fee', 'total_rec_prncp', 'total_rev_hi_lim', 'verification_status', 'zip_code']\n"
     ]
    }
   ],
   "source": [
    "threshold_df = local_df\n",
    "print(analytics)\n",
    "print(sorted(threshold_df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature segmentations\n",
    "\n",
    "datetimetypes = ['issue_d', 'last_pymnt_d', 'earliest_cr_line', 'last_credit_pull_d' ]\n",
    "\n",
    "date_identifiers = ['issue_month', 'last_p_month','earliest_cr_line_month', 'last_credit_pull_month',\n",
    "                   'int_rate', 'installment']\n",
    "\n",
    "redundants = ['grade','home_ownership']\n",
    "\n",
    "not_possible_to_know_at_decision_time = [\n",
    "    'funded_amnt', 'funded_amnt_inv',\n",
    "    'collection_recovery_fee', 'debt_settlement_flag', \n",
    "    'hardship_flag', \n",
    "    'last_pymnt_amnt', 'loan_status', \n",
    "    'out_prncp', 'out_prncp_inv',\n",
    "    'pymnt_plan', 'recoveries', 'total_pymnt', 'total_pymnt_inv', \n",
    "    'total_rec_int', 'total_rec_late_fee', 'total_rec_prncp'\n",
    "]\n",
    "\n",
    "too_many = ['emp_title', 'title', 'zip_code']\n",
    "\n",
    "exclude_features = datetimetypes + date_identifiers + redundants + not_possible_to_know_at_decision_time + too_many\n",
    "\n",
    "features = [col for col in threshold_df.columns if col not in exclude_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "term                    2\n",
       "sub_grade              35\n",
       "verification_status     3\n",
       "purpose                14\n",
       "addr_state             51\n",
       "initial_list_status     2\n",
       "application_type        2\n",
       "disbursement_method     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_df[features].select_dtypes(['object']).apply(pd.Series.nunique, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The encoded_df is ready for preprocessing. The excluded_df is already preprocessed.\n",
    "encoded_df = threshold_df[features].copy()\n",
    "exclude_df = threshold_df[exclude_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loan_amnt', 'term', 'sub_grade', 'emp_length', 'annual_inc',\n",
       "       'verification_status', 'purpose', 'addr_state', 'dti', 'delinq_2yrs',\n",
       "       'inq_last_6mths', 'open_acc', 'pub_rec', 'revol_bal', 'revol_util',\n",
       "       'total_acc', 'initial_list_status', 'collections_12_mths_ex_med',\n",
       "       'policy_code', 'application_type', 'acc_now_delinq', 'tot_coll_amt',\n",
       "       'tot_cur_bal', 'total_rev_hi_lim', 'acc_open_past_24mths',\n",
       "       'avg_cur_bal', 'bc_open_to_buy', 'bc_util', 'chargeoff_within_12_mths',\n",
       "       'delinq_amnt', 'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op',\n",
       "       'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc',\n",
       "       'mths_since_recent_bc', 'mths_since_recent_inq',\n",
       "       'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl',\n",
       "       'num_bc_sats', 'num_bc_tl', 'num_il_tl', 'num_op_rev_tl',\n",
       "       'num_rev_accts', 'num_rev_tl_bal_gt_0', 'num_sats', 'num_tl_120dpd_2m',\n",
       "       'num_tl_30dpd', 'num_tl_90g_dpd_24m', 'num_tl_op_past_12m',\n",
       "       'pct_tl_nvr_dlq', 'percent_bc_gt_75', 'pub_rec_bankruptcies',\n",
       "       'tax_liens', 'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit',\n",
       "       'total_il_high_credit_limit', 'disbursement_method',\n",
       "       'earliest_cr_line_age', 'TotalGain', 'LoanStatus', 'LifeOfLoan',\n",
       "       'PvGain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop sub_grade, addr_state\n",
    "encoded_df = encoded_df.drop(['sub_grade','addr_state','purpose'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('addr_state')\n",
    "features.remove('sub_grade')\n",
    "features.remove('purpose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term\n",
      "initial_list_status\n",
      "application_type\n",
      "disbursement_method\n",
      "4 columns were label encoded.\n"
     ]
    }
   ],
   "source": [
    "# label encode the binary categories\n",
    "from sklearn import preprocessing\n",
    "count = 0\n",
    "\n",
    "for col in features:\n",
    "    try:\n",
    "        if encoded_df[col].dtype == 'object':\n",
    "            if len(list(encoded_df[col].unique())) <= 2:     \n",
    "                le = preprocessing.LabelEncoder()\n",
    "                encoded_df[col] = le.fit_transform(encoded_df[col])\n",
    "                count += 1\n",
    "                print (col)\n",
    "    except:\n",
    "        print (col)\n",
    "            \n",
    "print('%d columns were label encoded.' % count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the rest of the object columns\n",
    "encoded_df = pd.get_dummies(encoded_df, sparse=True)\n",
    "\n",
    "# After Encode，Issue months from: 0 to 138 means from: Jun-2007 to Dec-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SimpleImputer to handle bad entries \n",
    "# Impute missing value by mean\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "simple_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "imputer = simple_imputer.fit(encoded_df)\n",
    "imputed = imputer.transform(encoded_df)\n",
    "\n",
    "encoded_df = pd.DataFrame(imputed, columns=encoded_df.columns, index=exclude_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Cases for 'homw_ownership' 'grade' 'purpose'\n",
    "# Instead of using dummy variables, we given different term different weights \n",
    "# It's proven to proferm better in this case \n",
    "\n",
    "exclude_df['grade'] = exclude_df['grade'].map({'A':7,'B':6,'C':5,'D':4,'E':3,'F':2,'G':1})\n",
    "exclude_df[\"home_ownership\"] = exclude_df[\"home_ownership\"].map({\"MORTGAGE\":6,\"RENT\":5,\"OWN\":4,\"OTHER\":3,\"NONE\":2,\"ANY\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glue the encoded_df and exclude_df back together\n",
    "\n",
    "data_df = pd.concat([encoded_df, exclude_df], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete features which canot be encoded \n",
    "features_to_delete = []\n",
    "for i in range(data_df.shape[1]):\n",
    "    if (data_df.iloc[:,i].dtype != \"float64\") and (data_df.iloc[:,i].dtype != \"int64\"):\n",
    "        features_to_delete.append(data_df.iloc[:,i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unencoded features\n",
    "for col in features_to_delete:\n",
    "    data_df = data_df.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['issue_d'] = local_df['issue_d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "processed_data_pkl = os.path.join(home_dir, \"processed_data.pkl\")\n",
    "\n",
    "processed_data = (data_df, exclude_features, analytics)\n",
    "\n",
    "with open(processed_data_pkl, 'wb') as f:\n",
    "    pickle.dump(processed_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
